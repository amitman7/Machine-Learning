{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6rF3OGsjtOSI",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score,explained_variance_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data inialize\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_pickle('/content/drive/My Drive/ass3.pickle')\n",
        "\n",
        "train = data['train']\n",
        "dev = data['dev']\n",
        "test = data['test']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "12UPsS-Ft3hS",
        "outputId": "83f93304-5921-4524-f201-08d6ddd1ff88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preliminary data analysis\n",
        "for part, d in data.items():\n",
        "    print(part, \"set:\\n\")\n",
        "    print(f\"Number of samples: {train.shape[0]}\")\n",
        "    print(f\"Number of features: {train.shape[1] -1}\\n\")\n",
        "    print(\"HEAD:\")\n",
        "    print(d.head(),\"\\n\") # prints first 5 rows of the data\n",
        "    print(\"STATISTICS:\")\n",
        "    print(d.describe(),\"\\n\") # prints descriptive statistics (count, mean, std, min, 25%, 50%, 75%, max)\n",
        "    print(\"IS NULL:\")\n",
        "    print(d.isnull().sum()) # checks if there are NaN or None in the columns\n",
        "    print(\"-----------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J-z5vGXKuFpm",
        "outputId": "12c6b57c-6530-4a84-84f4-f8eb6bb31190"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:\n",
            "\n",
            "Number of samples: 12384\n",
            "Number of features: 8\n",
            "\n",
            "HEAD:\n",
            "           f0    f1        f2        f3      f4        f5     f6      f7  \\\n",
            "14981  4.0391  15.0  6.297710  0.992366   334.0  2.549618  32.72 -116.99   \n",
            "6614   4.7241  46.0  5.375758  0.954545   753.0  2.281818  34.17 -118.10   \n",
            "14233  3.3553   7.0  5.229213  1.101124  1304.0  2.930337  32.70 -117.01   \n",
            "1802   1.3929  52.0  5.000000  0.953488   126.0  2.930233  37.92 -122.36   \n",
            "6030   1.6006  52.0  4.427083  1.017361  1246.0  2.163194  34.07 -117.75   \n",
            "\n",
            "       target  \n",
            "14981   1.695  \n",
            "6614    2.796  \n",
            "14233   1.322  \n",
            "1802    1.042  \n",
            "6030    1.462   \n",
            "\n",
            "STATISTICS:\n",
            "                 f0            f1            f2            f3            f4  \\\n",
            "count  12210.000000  12244.000000  12226.000000  12228.000000  12215.000000   \n",
            "mean       3.872771     28.630595      5.420978      1.096626   1426.830618   \n",
            "std        1.919183     12.566127      2.382548      0.471398   1103.528284   \n",
            "min        0.499900      1.000000      0.846154      0.500000      3.000000   \n",
            "25%        2.555600     18.000000      4.430232      1.006386    786.000000   \n",
            "50%        3.534100     29.000000      5.218429      1.049202   1170.000000   \n",
            "75%        4.745975     37.000000      6.043349      1.099202   1739.000000   \n",
            "max       15.000100     52.000000    132.533333     34.066667  28566.000000   \n",
            "\n",
            "                 f5            f6            f7        target  \n",
            "count  12242.000000  12233.000000  12236.000000  12384.000000  \n",
            "mean       3.144714     35.626833   -119.561040      2.066362  \n",
            "std       13.440452      2.133539      1.996646      1.147908  \n",
            "min        0.692308     32.550000   -124.350000      0.149990  \n",
            "25%        2.428571     33.940000   -121.790000      1.198000  \n",
            "50%        2.816384     34.250000   -118.490000      1.798000  \n",
            "75%        3.276456     37.710000   -118.020000      2.646000  \n",
            "max     1243.333333     41.950000   -114.550000      5.000010   \n",
            "\n",
            "IS NULL:\n",
            "f0        174\n",
            "f1        140\n",
            "f2        158\n",
            "f3        156\n",
            "f4        169\n",
            "f5        142\n",
            "f6        151\n",
            "f7        148\n",
            "target      0\n",
            "dtype: int64\n",
            "-----------------------------\n",
            "\n",
            "dev set:\n",
            "\n",
            "Number of samples: 12384\n",
            "Number of features: 8\n",
            "\n",
            "HEAD:\n",
            "          f0    f1        f2        f3      f4        f5     f6      f7  \\\n",
            "1473  3.2500  45.0  4.800595  1.005952   865.0  2.574405  37.97 -122.03   \n",
            "657   3.4583  43.0  5.599265  1.023897  1333.0  2.450368  37.70 -122.13   \n",
            "2686  2.4063  35.0  4.977987  1.069182   933.0  2.933962  32.97 -115.53   \n",
            "7197  2.2390  37.0  3.697552  1.013986  2842.0  4.968531  34.03 -118.18   \n",
            "8980  3.9643  46.0  5.526316  1.052632    69.0  3.631579  34.00 -118.41   \n",
            "\n",
            "      target  \n",
            "1473   1.511  \n",
            "657    1.837  \n",
            "2686   0.707  \n",
            "7197   1.213  \n",
            "8980   2.750   \n",
            "\n",
            "STATISTICS:\n",
            "                f0           f1           f2           f3            f4  \\\n",
            "count  4128.000000  4128.000000  4128.000000  4128.000000   4128.000000   \n",
            "mean      3.866869    28.540213     5.418337     1.093066   1408.653585   \n",
            "std       1.836324    12.718279     2.273679     0.437596   1101.425596   \n",
            "min       0.499900     1.000000     1.378486     0.333333     13.000000   \n",
            "25%       2.590200    18.000000     4.457824     1.006226    784.750000   \n",
            "50%       3.529450    28.000000     5.240401     1.048182   1153.500000   \n",
            "75%       4.773500    37.000000     6.048864     1.100941   1699.000000   \n",
            "max      15.000100    52.000000    62.422222    15.312500  13251.000000   \n",
            "\n",
            "                f5           f6           f7       target  \n",
            "count  4128.000000  4128.000000  4128.000000  4128.000000  \n",
            "mean      2.961756    35.633576  -119.583571     2.072209  \n",
            "std       1.547846     2.136005     2.004239     1.144698  \n",
            "min       1.215873    32.560000  -124.260000     0.149990  \n",
            "25%       2.426937    33.940000  -121.810000     1.213750  \n",
            "50%       2.815853    34.270000  -118.500000     1.810500  \n",
            "75%       3.290894    37.720000  -117.990000     2.657250  \n",
            "max      63.750000    41.800000  -114.490000     5.000010   \n",
            "\n",
            "IS NULL:\n",
            "f0        0\n",
            "f1        0\n",
            "f2        0\n",
            "f3        0\n",
            "f4        0\n",
            "f5        0\n",
            "f6        0\n",
            "f7        0\n",
            "target    0\n",
            "dtype: int64\n",
            "-----------------------------\n",
            "\n",
            "test set:\n",
            "\n",
            "Number of samples: 12384\n",
            "Number of features: 8\n",
            "\n",
            "HEAD:\n",
            "           f0    f1        f2        f3      f4        f5     f6      f7  \\\n",
            "6111   2.6619  25.0  4.090426  1.138298  2868.0  3.813830  34.13 -117.90   \n",
            "17742  6.2340   7.0  6.511551  1.082508  1047.0  3.455446  37.31 -121.78   \n",
            "79     2.0114  38.0  4.412903  1.135484   344.0  2.219355  37.80 -122.28   \n",
            "13150  4.6477  27.0  6.098214  1.241071  1230.0  3.660714  36.92 -121.47   \n",
            "527    3.1771  52.0  4.827907  1.023256   482.0  2.241860  37.77 -122.25   \n",
            "\n",
            "       target  \n",
            "6111    1.176  \n",
            "17742   2.922  \n",
            "79      1.313  \n",
            "13150   2.659  \n",
            "527     2.102   \n",
            "\n",
            "STATISTICS:\n",
            "                f0           f1           f2           f3            f4  \\\n",
            "count  4128.000000  4128.000000  4128.000000  4128.000000   4128.000000   \n",
            "mean      3.866247    28.679506     5.463992     1.101980   1442.645591   \n",
            "std       1.900516    12.485911     2.923525     0.522311   1236.273409   \n",
            "min       0.499900     2.000000     0.888889     0.444444      5.000000   \n",
            "25%       2.562500    18.000000     4.449079     1.005519    793.750000   \n",
            "50%       3.549400    29.000000     5.254936     1.048229   1167.000000   \n",
            "75%       4.729500    37.000000     6.088846     1.099634   1731.500000   \n",
            "max      15.000100    52.000000   141.909091    25.636364  35682.000000   \n",
            "\n",
            "                f5           f6           f7       target  \n",
            "count  4128.000000  4128.000000  4128.000000  4128.000000  \n",
            "mean      2.963794    35.647742  -119.580371     2.071497  \n",
            "std       1.085866     2.147442     2.020828     1.181218  \n",
            "min       1.060606    32.540000  -124.210000     0.225000  \n",
            "25%       2.439835    33.920000  -121.810000     1.187250  \n",
            "50%       2.833591    34.250000  -118.500000     1.781000  \n",
            "75%       3.286291    37.720000  -117.990000     2.650000  \n",
            "max      41.214286    41.780000  -114.310000     5.000010   \n",
            "\n",
            "IS NULL:\n",
            "f0        0\n",
            "f1        0\n",
            "f2        0\n",
            "f3        0\n",
            "f4        0\n",
            "f5        0\n",
            "f6        0\n",
            "f7        0\n",
            "target    0\n",
            "dtype: int64\n",
            "-----------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data to X and y\n",
        "X_train = train.iloc[:, :-1]\n",
        "y_train = train.iloc[:, -1]\n",
        "X_dev = dev.iloc[:, :-1]\n",
        "y_dev = dev.iloc[:, -1]\n",
        "X_test = test.iloc[:, :-1]\n",
        "y_test = test.iloc[:, -1]"
      ],
      "metadata": {
        "id": "RZIOWTiNzx2r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **preprocessing**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7UXmzp_czFiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation for NULL values\n",
        "X_train_imputed = X_train.copy()\n",
        "for col in X_train_imputed.columns:\n",
        "    if (X_train_imputed[col].isnull().sum() > 0):\n",
        "       imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "       imputer = imputer.fit(X_train_imputed[[col]])\n",
        "       X_train_imputed[col] = imputer.transform(X_train_imputed[[col]])\n",
        "\n",
        "# Standardization\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train_imputed) # fit scaler using only train data to avoid data leakage\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train_imputed)\n",
        "X_dev_scaled = scaler.transform(X_dev)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TFQCguLgw4n0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree Regressor**\n",
        "\n",
        "---\n",
        "### **hyperparameter search**\n",
        "\n",
        "**'criterion'** - which function to use to measure the impurity of a split.  \n",
        "**'splitter'** - which strategy to split each node. best - best split, random - the best random split. gives randomness into process.  \n",
        "**'max_depth'** - maximum depth of the tree.  \n",
        "**'min_samples_split**' - minimum number of samples required to split an internal node.  \n",
        "**'min_samples_leaf'** - minimum number of samples required to be at a leaf node.  \n",
        "\n"
      ],
      "metadata": {
        "id": "T4GzPQoy4yxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# both models are after Imputation - DecisionTreeRegressor can't run with null values\n",
        "model_default = DecisionTreeRegressor()\n",
        "model_default.fit(X_train_imputed, y_train)\n",
        "y_pred = model_default.predict(X_dev)\n",
        "mse = mean_squared_error(y_dev, y_pred)\n",
        "\n",
        "print(\"Dev mse before hyperparameter search:\")\n",
        "print(f'Without Standardization : {mse}')\n",
        "\n",
        "model_default = DecisionTreeRegressor()\n",
        "model_default.fit(X_train_scaled, y_train)\n",
        "y_pred = model_default.predict(X_dev_scaled)\n",
        "mse_scaled = mean_squared_error(y_dev, y_pred)\n",
        "print(f'With Standardization : {mse_scaled}')\n",
        "\n",
        "\"\"\" ---------------------------------------------------------------------------------------------------\"\"\"\n",
        "# hyperparameter search\n",
        "\n",
        "if (mse_scaled < mse):\n",
        "  X_train_grid = X_train_scaled.copy()\n",
        "  x_dev_grid = X_dev_scaled.copy()\n",
        "  print(\"Using Standardization made the performance better\\n\")\n",
        "else:\n",
        "  X_train_grid = X_train_scaled.copy()\n",
        "  x_dev_grid = X_dev_scaled.copy()\n",
        "  print(\"Using Standardization made the performance worse\\n\")\n",
        "\n",
        "\n",
        "model = DecisionTreeRegressor()\n",
        "params = {\n",
        "    'criterion': ['squared_error', 'friedman_mse'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 5],\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=params,n_jobs=-1)\n",
        "grid_search.fit(X_train_grid, y_train)\n",
        "print(f\"The best Parameters:{grid_search.best_params_}\\n\")\n",
        "grid_model = grid_search.best_estimator_\n",
        "y_pred = grid_model.predict(x_dev_grid)\n",
        "\n",
        "# Evaluate model\n",
        "mse = mean_squared_error(y_dev, y_pred)\n",
        "mae = mean_absolute_error(y_dev, y_pred)\n",
        "r2 = r2_score(y_dev, y_pred)\n",
        "evs = explained_variance_score(y_dev, y_pred)\n",
        "\n",
        "print(\"Metrics evaluate after hyperparameter search :\")\n",
        "print(f\"mse: {mse}\")\n",
        "print(f\"mae: {mae}\")\n",
        "print(f\"r2: {r2}\")\n",
        "print(f\"evs: {evs}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBzmsOxY4-A3",
        "outputId": "bbfb07b2-5691-4371-f210-f78efeaf3b35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev mse before hyperparameter search:\n",
            "Without Standardization : 0.5865978097325582\n",
            "With Standardization : 0.5906748645632509\n",
            "Using Standardization made the performance worse\n",
            "\n",
            "The best Parameters:{'criterion': 'squared_error', 'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "\n",
            "Metrics evaluate after hyperparameter search :\n",
            "mse: 0.42858973803745487\n",
            "mae: 0.4428844099098646\n",
            "r2: 0.6728364477937049\n",
            "evs: 0.6728742270482152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "3PJbrZ7cHXP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Linear Regression\")\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_imputed, y_train)\n",
        "y_pred = model.predict(X_dev)\n",
        "\n",
        "mse = mean_squared_error(y_dev, y_pred)\n",
        "\n",
        "print(\"Dev mse before hyperparameter search:\")\n",
        "print(f'Without Standardization : {mse}')\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred = model.predict(X_dev_scaled)\n",
        "\n",
        "mse_scaled = mean_squared_error(y_dev, y_pred)\n",
        "print(f'With Standardization : {mse_scaled}')\n",
        "\n",
        "if (mse_scaled < mse):\n",
        "  X_train_grid = X_train_scaled.copy()\n",
        "  x_dev_grid = X_dev_scaled.copy()\n",
        "  print(\"Using Standardization made the performance better\\n\")\n",
        "else:\n",
        "  X_train_grid = X_train_imputed.copy()\n",
        "  x_dev_grid = X_dev.copy()\n",
        "  print(\"Using Standardization made the performance worse\\n\")\n",
        "\n",
        "mse = mean_squared_error(y_dev, y_pred)\n",
        "mae = mean_absolute_error(y_dev, y_pred)\n",
        "r2 = r2_score(y_dev, y_pred)\n",
        "evs = explained_variance_score(y_dev, y_pred)\n",
        "\n",
        "print(\"Metrics evaluate after hyperparameter search :\")\n",
        "print(f\"mse: {mse}\")\n",
        "print(f\"mae: {mae}\")\n",
        "print(f\"r2: {r2}\")\n",
        "print(f\"evs: {evs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8uX2UG6HWK3",
        "outputId": "62d1e123-6241-468c-e748-ccb0899f675b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression\n",
            "Dev mse before hyperparameter search:\n",
            "Without Standardization : 0.5229043349016068\n",
            "With Standardization : 0.5229043349016071\n",
            "Using Standardization made the performance worse\n",
            "\n",
            "Metrics evaluate after hyperparameter search :\n",
            "mse: 0.5229043349016071\n",
            "mae: 0.5231571750489639\n",
            "r2: 0.6008414936534725\n",
            "evs: 0.6008586157921586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVR"
      ],
      "metadata": {
        "id": "3TJnzo5uHa6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVR\")\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X_train_imputed, y_train)\n",
        "y_pred = model.predict(X_dev)\n",
        "\n",
        "mse = mean_squared_error(y_dev, y_pred)\n",
        "\n",
        "print(\"Dev MSE before hyperparameter search:\")\n",
        "print(f'Without Standardization: {mse}')\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred = model.predict(X_dev_scaled)\n",
        "\n",
        "mse_scaled = mean_squared_error(y_dev, y_pred)\n",
        "print(f'With Standardization: {mse_scaled}')\n",
        "\n",
        "if mse_scaled < mse:\n",
        "    X_train_grid = X_train_scaled.copy()\n",
        "    X_dev_grid = X_dev_scaled.copy()\n",
        "    print(\"Using Standardization made the performance better\\n\")\n",
        "else:\n",
        "    X_train_grid = X_train_imputed.copy()\n",
        "    X_dev_grid = X_dev.copy()\n",
        "    print(\"Using Standardization made the performance worse\\n\")\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(SVR(), param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train_grid, y_train)\n",
        "\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_dev_pred = best_model.predict(X_dev_grid)\n",
        "mse = mean_squared_error(y_dev, y_dev_pred)\n",
        "mae = mean_absolute_error(y_dev, y_dev_pred)\n",
        "r2 = r2_score(y_dev, y_dev_pred)\n",
        "evs = explained_variance_score(y_dev, y_dev_pred)\n",
        "\n",
        "print(\"Metrics evaluate after hyperparameter search:\")\n",
        "print(f\"mse: {mse}\")\n",
        "print(f\"mae: {mae}\")\n",
        "print(f\"r2: {r2}\")\n",
        "print(f\"evs: {evs}\")\n",
        "\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "evs_test = explained_variance_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Final evaluation on the test set:\")\n",
        "print(f\"mse: {mse_test}\")\n",
        "print(f\"mae: {mae_test}\")\n",
        "print(f\"r2: {r2_test}\")\n",
        "print(f\"evs: {evs_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiaKLz5zHdqM",
        "outputId": "b24f0132-6902-4649-b653-6a9514d75e2f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVR\n",
            "Dev MSE before hyperparameter search:\n",
            "Without Standardization: 1.351774899648952\n",
            "With Standardization: 0.4728811519237644\n",
            "Using Standardization made the performance better\n",
            "\n",
            "Best parameters found: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Metrics evaluate after hyperparameter search:\n",
            "mse: 0.4401560430608194\n",
            "mae: 0.4406136707664648\n",
            "r2: 0.6640073203053216\n",
            "evs: 0.6753909057952072\n",
            "Final evaluation on the test set:\n",
            "mse: 0.4366549802026933\n",
            "mae: 0.4418450137195807\n",
            "r2: 0.6869719943721015\n",
            "evs: 0.6983829328518527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, param_grid, model_name):\n",
        "    print(model_name)\n",
        "\n",
        "    model.fit(X_train_imputed, y_train)\n",
        "    y_pred = model.predict(X_dev)\n",
        "    mse = mean_squared_error(y_dev, y_pred)\n",
        "    print(f\"Dev MSE before hyperparameter search without Standardization: {mse}\")\n",
        "\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_dev_scaled)\n",
        "    mse_scaled = mean_squared_error(y_dev, y_pred)\n",
        "    print(f\"Dev MSE before hyperparameter search with Standardization: {mse_scaled}\")\n",
        "\n",
        "    if mse_scaled < mse:\n",
        "        X_train_grid = X_train_scaled.copy()\n",
        "        X_dev_grid = X_dev_scaled.copy()\n",
        "        print(\"Using Standardization made the performance better\\n\")\n",
        "    else:\n",
        "        X_train_grid = X_train_imputed.copy()\n",
        "        X_dev_grid = X_dev.copy()\n",
        "        print(\"Using Standardization made the performance worse\\n\")\n",
        "\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
        "    grid_search.fit(X_train_grid, y_train)\n",
        "    print(f\"Best parameters found for {model_name}: {grid_search.best_params_}\")\n",
        "\n",
        "    # Evaluate the best model on the dev set\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_dev_pred = best_model.predict(X_dev_grid)\n",
        "    mse = mean_squared_error(y_dev, y_dev_pred)\n",
        "    mae = mean_absolute_error(y_dev, y_dev_pred)\n",
        "    r2 = r2_score(y_dev, y_dev_pred)\n",
        "    evs = explained_variance_score(y_dev, y_dev_pred)\n",
        "\n",
        "    print(f\"Metrics evaluated after hyperparameter search for {model_name}:\")\n",
        "    print(f\"mse: {mse}\")\n",
        "    print(f\"mae: {mae}\")\n",
        "    print(f\"r2: {r2}\")\n",
        "    print(f\"evs: {evs}\")\n",
        "\n",
        "    y_test_pred = best_model.predict(X_test_scaled)\n",
        "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "    evs_test = explained_variance_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Final evaluation on the test set for {model_name}:\")\n",
        "    print(f\"mse: {mse_test}\")\n",
        "    print(f\"mae: {mae_test}\")\n",
        "    print(f\"r2: {r2_test}\")\n",
        "    print(f\"evs: {evs_test}\\n\")\n"
      ],
      "metadata": {
        "id": "uGzIqTfiIUDs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_adaboost = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "evaluate_model(AdaBoostRegressor(), param_grid_adaboost, \"AdaBoost\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA942GP6IlXV",
        "outputId": "403172a7-3199-4a04-d57e-ae812694959b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost\n",
            "Dev MSE before hyperparameter search without Standardization: 0.6423567302346261\n",
            "Dev MSE before hyperparameter search with Standardization: 0.7140307081710622\n",
            "Using Standardization made the performance worse\n",
            "\n",
            "Best parameters found for AdaBoost: {'learning_rate': 0.1, 'n_estimators': 50}\n",
            "Metrics evaluated after hyperparameter search for AdaBoost:\n",
            "mse: 0.562585808051947\n",
            "mae: 0.5855966469444533\n",
            "r2: 0.5705506804107406\n",
            "evs: 0.5822001431844692\n",
            "Final evaluation on the test set for AdaBoost:\n",
            "mse: 1.4324266232792904\n",
            "mae: 0.9819416759091022\n",
            "r2: -0.02687400676222884\n",
            "evs: 0.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_gradientboosting = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "evaluate_model(GradientBoostingRegressor(), param_grid_gradientboosting, \"GradientBoosting\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNuzZR9uImpK",
        "outputId": "22af1f0f-0cdf-4de4-e1e6-701a0e7f23ce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GradientBoosting\n",
            "Dev MSE before hyperparameter search without Standardization: 0.29576214702115255\n",
            "Dev MSE before hyperparameter search with Standardization: 0.2993886071180408\n",
            "Using Standardization made the performance worse\n",
            "\n",
            "Best parameters found for GradientBoosting: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
            "Metrics evaluated after hyperparameter search for GradientBoosting:\n",
            "mse: 0.22885056351991087\n",
            "mae: 0.31168939073898055\n",
            "r2: 0.8253071489102165\n",
            "evs: 0.8253456224339\n",
            "Final evaluation on the test set for GradientBoosting:\n",
            "mse: 1.6177562061542734\n",
            "mae: 1.093863752279205\n",
            "r2: -0.1597325617803731\n",
            "evs: 0.004603967012443144\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_xgboost = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "evaluate_model(XGBRegressor(objective='reg:squarederror'), param_grid_xgboost, \"XGBoost\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHQ10n4lIiw9",
        "outputId": "a4a3d8f7-bdb4-4c05-e287-efc53981725d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost\n",
            "Dev MSE before hyperparameter search without Standardization: 0.23387224399644888\n",
            "Dev MSE before hyperparameter search with Standardization: 0.23387224399644888\n",
            "Using Standardization made the performance worse\n",
            "\n",
            "Best parameters found for XGBoost: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
            "Metrics evaluated after hyperparameter search for XGBoost:\n",
            "mse: 0.21462622481063584\n",
            "mae: 0.3026530530052014\n",
            "r2: 0.8361652837811574\n",
            "evs: 0.836166190593622\n",
            "Final evaluation on the test set for XGBoost:\n",
            "mse: 1.608914983314919\n",
            "mae: 0.9111525648254386\n",
            "r2: -0.1533944905841389\n",
            "evs: -0.0005290625524645431\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best estimator was XGBoost, The results :\n",
        "\n",
        "Final evaluation on the test set for XGBoost:\n",
        "\n",
        "mse: 1.608914983314919\n",
        "\n",
        "mae: 0.9111525648254386\n",
        "\n",
        "r2: -0.1533944905841389\n",
        "\n",
        "evs: -0.0005290625524645431"
      ],
      "metadata": {
        "id": "rQVDrSDULcjC"
      }
    }
  ]
}